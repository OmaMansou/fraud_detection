{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCXloA6pDxgk"
      },
      "outputs": [],
      "source": [
        "#  Import packages\n",
        "\n",
        "# Numpy,Pandas\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "\n",
        "# matplotlib,seaborn,pyecharts\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from matplotlib.pyplot import figure\n",
        "import plotly.graph_objects as go\n",
        "# plt.style.use('ggplot')  \n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "%matplotlib inline\n",
        "import missingno as msno\n",
        "\n",
        "# ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')  \n",
        " \n",
        "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
        "\n",
        "#importing the models to use \n",
        "from sklearn.ensemble import IsolationForest\n",
        "# import / install deep svdd , see https://pypi.org/project/deep-svdd/ for more details \n",
        "# !pip install deep-svdd ##execute this just one time \n",
        "#from dsvdd import *\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "# importing metrics\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-o8zOb-Y3SzG",
        "outputId": "793c7214-ba69-4552-c0b6-6dc142374888"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# prepare data \n",
        "#mounting the driver so we can access the content of google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# reading the dataset\n",
        "path = '/content/drive/MyDrive/'\n",
        "\n",
        "train_data = pd.read_csv(path + 'Copie de train_dataset.csv')\n",
        "valid_data = pd.read_csv(path + 'Copie de valid_dataset.csv')\n",
        "test_data = pd.read_csv(path + 'Copie de test_dataset.csv')\n",
        "\n",
        "\n",
        "train_fraud = train_data.pop('fraud')\n",
        "test_fraud = test_data.pop('fraud')\n",
        "valid_fraud  = valid_data.pop('fraud')\n",
        "\n",
        "try:\n",
        "  data = pd.read_pickle(path + 'fraud_dataset.pkl')\n",
        "except:\n",
        "  data = pd.read_csv(path + 'fraud_dataset.csv')\n",
        "  # peakle data \n",
        "  data.to_pickle('/content/drive/MyDrive/fraud_dataset.pkl')\n",
        "\n",
        "\n",
        "data['hour'] = pd.to_datetime(data['datetime']).dt.hour\n",
        "data.drop('datetime', axis = 1, inplace = True)\n",
        "# dropping the useless column 'Unnamed: 0'\n",
        "data.drop('Unnamed: 0', axis = 1, inplace = True)\n",
        "\n",
        "train_columns = set(['acquirerid', 'agriculture_list', 'rollingsum_card_merchant_24h','bankid', 'batchamount','card','emv','cup','construction_list','mean_merchant_amount','mcc', 'list_bankid_ci', 'list_bankid_b', 'fuel_list', 'pospayenvcode','merchant', 'medic_list',\n",
        "                   'rollingcount_card_merchant_600s','riskmerchant', 'resp_code', 'rollingcount_merchant_24h','rollingcount_merchant_900s','rollingsum_card_24h','rollingsum_merchant_24h','rollingsum_merchant_900s',\n",
        "                   'hour', 'trc', 'travel_list', 'terminal', 'super_market_list'])\n",
        "\n",
        "train_columns = set(train_columns) & set(train_data.columns) & set(test_data.columns) & set(valid_data.columns)\n",
        "train_columns = list(train_columns)\n",
        "\n",
        "# let's shuffle the data first\n",
        "data = data.sample(frac=1).reset_index(drop = True)\n",
        "\n",
        "data  = data.iloc[:200000]\n",
        "train_data_ = data[:150000]\n",
        "train_data_ = train_data_[train_data_.fraud == 0]\n",
        "X_train = train_data_[train_columns]\n",
        "\n",
        "# test_data = data[150000:]\n",
        "# X_test,Y_test = test_data[train_columns], test_data['fraud']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f87mLstIqjXj"
      },
      "outputs": [],
      "source": [
        "train_data, test_data, valid_data = train_data[train_columns], test_data[train_columns], valid_data[train_columns]\n",
        "\n",
        "\n",
        "# Normalizing data \n",
        "from sklearn.preprocessing import StandardScaler as sc\n",
        "\n",
        "\n",
        "# #train_data.drop(['Unnamed: 0', 'cup'], axis = 1, inplace = True)\n",
        "# #test_data.drop(['Unnamed: 0', 'cup'], axis = 1, inplace = True)\n",
        "# valid_data.drop(['Unnamed: 0', 'cup'], axis = 1, inplace = True)\n",
        "\n",
        "# model = sc()\n",
        "\n",
        "X_train = X_train.values\n",
        "# X_train = model.fit_transform(X = X_train)\n",
        "\n",
        "train_data = train_data.values\n",
        "# train_data = model.transform(X = train_data)\n",
        "\n",
        "test_data = test_data.values\n",
        "# test_data = model.transform(X = test_data)\n",
        "\n",
        "valid_data = valid_data.values\n",
        "# valid_data = model.transform(X = valid_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uIw1d8qgFBx"
      },
      "outputs": [],
      "source": [
        "# I need to define the architecture of the network\n",
        "def network_model(input_shape, H=10):\n",
        "\n",
        "  model = keras.models.Sequential()\n",
        "\n",
        "  model.add(keras.layers.Dense(units= input_shape ,activation='relu', use_bias=False))\n",
        "  model.add(keras.layers.Dropout(0.2))\n",
        "  model.add(keras.layers.Dense(units= 16, activation='relu', use_bias=False))\n",
        "  model.add(keras.layers.Dropout(0.2))\n",
        "  model.add(keras.layers.Dense(units= 8, activation='relu', use_bias=False))\n",
        "  model.add(keras.layers.Dropout(0.2))\n",
        "  model.add(keras.layers.Dense(units= 4, activation='relu', use_bias=False))\n",
        "  model.add(keras.layers.Dense(units= H, activation='relu', use_bias=False))\n",
        "  \n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypx_u0knf7oX"
      },
      "outputs": [],
      "source": [
        "from contextlib import contextmanager\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "__all__ = ['plot_most_normal_and_abnormal_images', 'task']\n",
        "\n",
        "\n",
        "@contextmanager\n",
        "def task(_=''):\n",
        "    yield"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEkQx9Pe7F8n"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from math import ceil\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from tensorflow import keras\n",
        "from tqdm import tqdm\n",
        "\n",
        "#from .utils import task\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "\n",
        "class DeepSVDD:\n",
        "  def __init__(self, keras_model, input_shape=(28, 28, 1), objective='one-class',\n",
        "                nu=0.1, representation_dim=32, batch_size=128, lr=1e-3):\n",
        "      self.represetation_dim = representation_dim\n",
        "      self.objective = objective\n",
        "      self.keras_model = keras_model\n",
        "      self.nu = nu\n",
        "      self.R = tf.compat.v1.get_variable('R', [], dtype=tf.float32, trainable=False)\n",
        "      self.c = tf.compat.v1.get_variable('c', [self.represetation_dim], dtype=tf.float32, trainable=False)\n",
        "      self.warm_up_n_epochs = 10\n",
        "      self.batch_size = batch_size\n",
        "\n",
        "      with task('Build graph'):\n",
        "          self.x = tf.compat.v1.placeholder(tf.float32, [None] + list(input_shape))\n",
        "          self.latent_op = self.keras_model(self.x)\n",
        "          self.dist_op = tf.reduce_sum(tf.square(self.latent_op - self.c), axis=-1)\n",
        "\n",
        "          if self.objective == 'soft-boundary':\n",
        "              self.score_op = self.dist_op - self.R ** 2\n",
        "              penalty = tf.maximum(self.score_op, tf.zeros_like(self.score_op))\n",
        "              self.loss_op = self.R ** 2 + (1 / self.nu) * penalty\n",
        "\n",
        "          else:  # one-class\n",
        "              self.score_op = self.dist_op\n",
        "              self.loss_op = self.score_op\n",
        "\n",
        "          opt = tf.compat.v1.train.AdamOptimizer(lr)\n",
        "          self.train_op = opt.minimize(self.loss_op)\n",
        "\n",
        "      config = tf.compat.v1.ConfigProto()\n",
        "      config.gpu_options.allow_growth = True\n",
        "      self.sess = tf.compat.v1.Session(config=config)\n",
        "      self.sess.run(tf.compat.v1.global_variables_initializer())\n",
        "\n",
        "  def __del__(self):\n",
        "      self.sess.close()\n",
        "\n",
        "  def fit(self, X, X_test, y_test, epochs=10, verbose=True):\n",
        "      N = X.shape[0]\n",
        "      BS = self.batch_size\n",
        "      BN = int(ceil(N / BS))\n",
        "\n",
        "      self.sess.run(tf.compat.v1.global_variables_initializer())\n",
        "      self._init_c(X)\n",
        "\n",
        "      ops = {\n",
        "          'train': self.train_op,\n",
        "          'loss': tf.reduce_mean(self.loss_op),\n",
        "          'dist': self.dist_op\n",
        "      }\n",
        "      keras.backend.set_learning_phase(True)\n",
        "\n",
        "      for i_epoch in range(epochs):\n",
        "          ind = np.random.permutation(N)\n",
        "          x_train = X[ind]\n",
        "          g_batch = tqdm(range(BN)) if verbose else range(BN)\n",
        "          for i_batch in g_batch:\n",
        "              x_batch = x_train[i_batch * BS: (i_batch + 1) * BS]\n",
        "              results = self.sess.run(ops, feed_dict={self.x: x_batch})\n",
        "\n",
        "              if self.objective == 'soft-boundary' and i_epoch >= self.warm_up_n_epochs:\n",
        "                  self.sess.run(tf.compat.v1.assign(self.R, self._get_R(results['dist'], self.nu)))\n",
        "\n",
        "          else:\n",
        "              if verbose:\n",
        "                  pred = self.predict(X_test)  # pred: large->fail small->pass\n",
        "                  auc = roc_auc_score(y_test, -pred)  # y_test: 1->pass 0->fail\n",
        "                  print('\\rEpoch: %3d AUROC: %.3f' % (i_epoch, auc))\n",
        "\n",
        "  def predict(self, X):\n",
        "      N = X.shape[0]\n",
        "      BS = self.batch_size\n",
        "      BN = int(ceil(N / BS))\n",
        "      scores = list()\n",
        "      keras.backend.set_learning_phase(False)\n",
        "\n",
        "      for i_batch in range(BN):\n",
        "          x_batch = X[i_batch * BS: (i_batch + 1) * BS]\n",
        "          s_batch = self.sess.run(self.score_op, feed_dict={self.x: x_batch})\n",
        "          scores.append(s_batch)\n",
        "\n",
        "      return np.concatenate(scores)\n",
        "\n",
        "  def _init_c(self, X, eps=1e-1):\n",
        "      N = X.shape[0]\n",
        "      BS = self.batch_size\n",
        "      BN = int(ceil(N / BS))\n",
        "      keras.backend.set_learning_phase(False)\n",
        "\n",
        "      with task('1. Get output'):\n",
        "          latent_sum = np.zeros(self.latent_op.shape[-1])\n",
        "          for i_batch in range(BN):\n",
        "              x_batch = X[i_batch * BS: (i_batch + 1) * BS]\n",
        "              latent_v = self.sess.run(self.latent_op, feed_dict={self.x: x_batch})\n",
        "              latent_sum += latent_v.sum(axis=0)\n",
        "\n",
        "          c = latent_sum / N\n",
        "\n",
        "      with task('2. Modify eps'):\n",
        "          c[(abs(c) < eps) & (c < 0)] = -eps\n",
        "          c[(abs(c) < eps) & (c > 0)] = eps\n",
        "\n",
        "      self.sess.run(tf.compat.v1.assign(self.c, c))\n",
        "\n",
        "  def _get_R(self, dist, nu):\n",
        "      return np.quantile(np.sqrt(dist), 1 - nu)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoGLVE811-P4"
      },
      "outputs": [],
      "source": [
        "# Now let's build our model\n",
        "\n",
        "input_shape = X_train.shape[1]\n",
        "tf.compat.v1.reset_default_graph()\n",
        "# build model and DeepSVDD\n",
        "keras_model = network_model(input_shape, 4)\n",
        "svdd = DeepSVDD(keras_model, input_shape= (input_shape,), representation_dim=4,\n",
        "                objective='one-class')\n",
        "\n",
        "\n",
        "# train DeepSVDD\n",
        "svdd.fit(X_train, valid_data, valid_fraud, epochs=10, verbose=False)\n",
        "\n",
        "# test DeepSVDD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyA1OvNTjaOd"
      },
      "outputs": [],
      "source": [
        "# score = svdd.predict(X_test)\n",
        "# # Now let's find the best threeshold \n",
        "# threeshold = np.quantile(svdd.predict(X_train),0.95) #setting threeshold\n",
        "# predicted = np.where(score>threeshold, 1,0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "Counter(test_fraud)"
      ],
      "metadata": {
        "id": "fDxtWz3mAl1X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4474bdbe-3e14-429e-a7ab-0af0a242c6b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 24980, 1: 20})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(valid_fraud)"
      ],
      "metadata": {
        "id": "VqtLvQT9A2XO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15db6043-15ee-42cf-ed0c-d6a9f21beab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 24974, 1: 26})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = svdd.predict(valid_data)\n",
        "y_true = valid_fraud\n",
        "threeshold = np.quantile(svdd.predict(train_data),0.95) #setting threeshold\n",
        "predicted = np.where(score>threeshold, 1,0)\n",
        "\n",
        "print(f'the recall is :{recall_score(y_true,predicted)}', end = '\\n')\n",
        "print(f'the precision is :{precision_score(y_true,predicted)}', end = '\\n')\n",
        "print(f'the f1 score is :{f1_score(y_true,predicted)}', end = '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-BDcCnb_m0y",
        "outputId": "1065e7e1-c2e8-4a2e-dbed-9fd02f4c5c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the recall is :0.4230769230769231\n",
            "the precision is :0.008258258258258258\n",
            "the f1 score is :0.016200294550810013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x195AogbwbKT"
      },
      "outputs": [],
      "source": [
        "score = svdd.predict(valid_data)\n",
        "y_true = test_fraud\n",
        "# Now let's find the best threeshold \n",
        "threeshold_quantiles = np.linspace(0,1,20)\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "f1_scores = []\n",
        "for threeshold_quantile in threeshold_quantiles:\n",
        "  threeshold = np.quantile(svdd.predict(train_data),threeshold_quantile) #setting threeshold\n",
        "  predicted = np.where(score>threeshold, 1,0)\n",
        "  recall_scores.append(recall_score(y_true,predicted))\n",
        "  precision_scores.append(precision_score(y_true,predicted))\n",
        "  f1_scores.append(f1_score(y_true,predicted))\n",
        "\n",
        "# plotting the figure "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04oX1qaXuAUe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "aee7b95b-56af-4c01-f0fe-a066d36675a4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"8ce8fec6-bac3-4afe-9ea3-8df1703e9591\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8ce8fec6-bac3-4afe-9ea3-8df1703e9591\")) {                    Plotly.newPlot(                        \"8ce8fec6-bac3-4afe-9ea3-8df1703e9591\",                        [{\"name\":\"recall\",\"x\":[0.0,0.05263157894736842,0.10526315789473684,0.15789473684210525,0.21052631578947367,0.2631578947368421,0.3157894736842105,0.3684210526315789,0.42105263157894735,0.47368421052631576,0.5263157894736842,0.5789473684210527,0.631578947368421,0.6842105263157894,0.7368421052631579,0.7894736842105263,0.8421052631578947,0.894736842105263,0.9473684210526315,1.0],\"y\":[1.0,0.95,0.85,0.85,0.7,0.7,0.6,0.6,0.55,0.55,0.45,0.45,0.4,0.35,0.35,0.3,0.3,0.25,0.15,0.0],\"type\":\"scatter\"},{\"name\":\"precision\",\"x\":[0.0,0.05263157894736842,0.10526315789473684,0.15789473684210525,0.21052631578947367,0.2631578947368421,0.3157894736842105,0.3684210526315789,0.42105263157894735,0.47368421052631576,0.5263157894736842,0.5789473684210527,0.631578947368421,0.6842105263157894,0.7368421052631579,0.7894736842105263,0.8421052631578947,0.894736842105263,0.9473684210526315,1.0],\"y\":[0.0008,0.0008036885072543463,0.0007629134317641251,0.0008121924418326884,0.0007148327801889201,0.0007644842461639273,0.0007043493572812115,0.0007618080243778568,0.0007605088495575221,0.0008373296795310954,0.0007609706603534285,0.0008589425462874594,0.0008686210640608035,0.0008786243253420359,0.0010532651218778213,0.0011175265412553548,0.0014955134596211367,0.0018201674554058974,0.002142857142857143,0.0],\"type\":\"scatter\"},{\"name\":\"f1_scores\",\"x\":[0.0,0.05263157894736842,0.10526315789473684,0.15789473684210525,0.21052631578947367,0.2631578947368421,0.3157894736842105,0.3684210526315789,0.42105263157894735,0.47368421052631576,0.5263157894736842,0.5789473684210527,0.631578947368421,0.6842105263157894,0.7368421052631579,0.7894736842105263,0.8421052631578947,0.894736842105263,0.9473684210526315,1.0],\"y\":[0.001598721023181455,0.001606018342420016,0.0015244585930143926,0.0016228342322562167,0.001428207090028054,0.0015273004963726614,0.0014070469601922965,0.001521683996956632,0.0015189174261253798,0.0016721137037318536,0.0015193719929095975,0.0017146123071061154,0.001733477789815818,0.00175284837861525,0.0021002100210021,0.0022267582111709034,0.0029761904761904765,0.003614022406938923,0.004225352112676056,0.0],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('8ce8fec6-bac3-4afe-9ea3-8df1703e9591');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import plotly.express as px\n",
        "\n",
        "fig = go.Figure()\n",
        "# adding traces \n",
        "names = ['recall', 'precision', 'f1_scores']\n",
        "for i,y in enumerate([recall_scores, precision_scores, f1_scores]):\n",
        "  fig.add_trace(go.Scatter(\n",
        "      x = threeshold_quantiles,\n",
        "      y = y,\n",
        "      name = names[i]\n",
        "  ))\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svdd.predict(valid_data)"
      ],
      "metadata": {
        "id": "28qp-Lb-INV3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cb51862-fb0a-4eee-f537-e1a1e457c973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([130705.734,  21263.645, 189284.28 , ..., 652565.   ,  90123.24 ,\n",
              "        22952.852], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGlhvKdi3ugg",
        "outputId": "cfd91f45-f69b-4e3e-d07f-6eb25cdd90ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([130705.734,  21263.645, 189284.28 , ..., 652565.   ,  90123.24 ,\n",
              "        22952.852], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting on test and valid_data \n",
        "# for valid_data \n",
        "score = pd.DataFrame({'valid_data' : svdd.predict(valid_data),\n",
        "                      'test_data' : svdd.predict(test_data)})\n",
        "score = pd.concat([score, pd.DataFrame({'train_data': svdd.predict(train_data)})], axis = 1)\n",
        "score.to_csv(\"drive/MyDrive/results_SVDD.csv\")\n"
      ],
      "metadata": {
        "id": "N6tTkZ2sFPo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGEL6GUb1a4s"
      },
      "outputs": [],
      "source": [
        "# import plotly.express as px\n",
        "\n",
        "# fig = go.Figure()\n",
        "# # adding traces \n",
        "# names = ['recall', 'precision', 'f1_scores']\n",
        "# for i,y in enumerate([recall_scores, precision_scores, f1_scores]):\n",
        "#   fig.add_trace(go.Scatter(\n",
        "#       x = threeshold_quantiles,\n",
        "#       y = y,\n",
        "#       name = names[i]\n",
        "#   ))\n",
        "# fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9yPsFgnmqbw"
      },
      "outputs": [],
      "source": [
        "best_threes = np.quantile(svdd.predict(train_data),0.947)\n",
        "predicted = np.where(score>best_threes, 1,0)\n",
        "y_true = test_fraud\n",
        "print(f'the recall is :{recall_score(y_true,predicted)}', end = '\\n')\n",
        "print(f'the precision is :{precision_score(y_true,predicted)}', end = '\\n')\n",
        "print(f'the f1 score is :{f1_score(y_true,predicted)}', end = '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8C1uXXm1uWTK"
      },
      "outputs": [],
      "source": [
        "estimators_number = np.arange(1,500,step = 50)\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "f1_scores = []\n",
        "y_true = Y_test\n",
        "\n",
        "for n_estimators in estimators_number:\n",
        "  model_if = IsolationForest(n_estimators = n_estimators, random_state=2022, max_features= 20).fit(X_train)\n",
        "  predicted = model_if.predict(X_test)\n",
        "  predicted = np.where(predicted == 1,0,1)\n",
        "  recall_scores.append(recall_score(y_true,predicted))\n",
        "  precision_scores.append(precision_score(y_true,predicted))\n",
        "  f1_scores.append(f1_score(y_true,predicted))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PxTHp7Uu3sbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnDWtJqM6L8M"
      },
      "outputs": [],
      "source": [
        "fig = go.Figure()\n",
        "# adding traces \n",
        "names = ['recall', 'precision', 'f1_scores']\n",
        "for i,y in enumerate([recall_scores, precision_scores, f1_scores]):\n",
        "  fig.add_trace(go.Scatter(\n",
        "      x = estimators_number,\n",
        "      y = y,\n",
        "      name = names[i]\n",
        "  ))\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89QR5iNouT_J"
      },
      "outputs": [],
      "source": [
        "# Pourquoi ça stagne ????"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIH2J7HfBCt0"
      },
      "outputs": [],
      "source": [
        "# Let's try to use some bayesian optimization:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_2-jU5GyqCP"
      },
      "source": [
        "# Bayesien optimization:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDlwNObb1HgP"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# reading the dataset\n",
        "path = '/content/drive/MyDrive/'\n",
        "try:\n",
        "  data = pd.read_pickle(path + 'fraud_dataset.pkl')\n",
        "except:\n",
        "  data = pd.read_csv(path + 'fraud_dataset.csv')\n",
        "  # peakle data \n",
        "  data.to_pickle('/content/drive/MyDrive/fraud_dataset.pkl')\n",
        "\n",
        "\n",
        "data['hour'] = pd.to_datetime(data['datetime']).dt.hour\n",
        "data.drop('datetime', axis = 1, inplace = True)\n",
        "# dropping the useless column 'Unnamed: 0'\n",
        "data.drop('Unnamed: 0', axis = 1, inplace = True)\n",
        "\n",
        "train_columns = ['acquirerid', 'agriculture_list', 'rollingsum_card_merchant_24h','bankid', 'batchamount','card','emv','cup','construction_list','mean_merchant_amount','mcc', 'list_bankid_ci', 'list_bankid_b', 'fuel_list', 'pospayenvcode','merchant', 'medic_list',\n",
        "                   'rollingcount_card_merchant_600s','riskmerchant', 'resp_code', 'rollingcount_merchant_24h','rollingcount_merchant_900s','rollingsum_card_24h','rollingsum_merchant_24h','rollingsum_merchant_900s',\n",
        "                   'hour', 'trc', 'travel_list', 'terminal', 'super_market_list']\n",
        "\n",
        "# let's shuffle the data first\n",
        "data = data.sample(frac=1).reset_index(drop = True)\n",
        "\n",
        "data  = data.iloc[:1000000]\n",
        "frauds = data.pop('fraud')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOH64X0fywS1"
      },
      "outputs": [],
      "source": [
        "#data, frauds = data.values, frauds.values\n",
        "# define search space\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "try:\n",
        "  from skopt import BayesSearchCV\n",
        "except:\n",
        "  !pip install scikit-optimize\n",
        "  from skopt import BayesSearchCV\n",
        "\n",
        "params = dict()\n",
        "params['n_estimators'] = (1, 1000, 'log-uniform')\n",
        "params['contamination'] = (0.01, 0.12, 'uniform')\n",
        "params['max_features'] = (1,30)\n",
        "params['bootstrap'] = [True, False]\n",
        "\n",
        "model_if = IsolationForest()\n",
        "\n",
        "# define evaluation\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "def custom_f1_score(estimator,X,y):\n",
        "  return f1_score(y, np.where(estimator.predict(X) == 1,0,1))\n",
        "  \n",
        "# define the search\n",
        "search = BayesSearchCV(estimator= model_if , search_spaces=params, n_jobs=-1, cv=cv, scoring = custom_f1_score)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CxVqNd7363v"
      },
      "outputs": [],
      "source": [
        "X = data[train_columns].values\n",
        "Y = frauds.values\n",
        "\n",
        "search.fit(X,frauds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hbjPrBCo7W6"
      },
      "outputs": [],
      "source": [
        "# Now let's implement Isolation forest \n",
        "\n",
        "\n",
        "model_if = IsolationForest(n_estimators = 100, random_state=2022).fit(train_data)\n",
        "\n",
        "predicted = pd.DataFrame({\n",
        "    'valid_data': model_if.predict(valid_data),\n",
        "    'test_data': model_if.predict(test_data)\n",
        "})\n",
        "\n",
        "predicted = pd.concat([score, pd.DataFrame({'train_data': model_if.predict(train_data)})], axis = 1)\n",
        "\n",
        "predicted.to_csv(\"drive/MyDrive/results_IsolationForest.csv\")\n",
        "# predicted = model_if.predict(X_test)\n",
        "# predicted = np.where(predicted == 1,0,1)\n",
        "\n",
        "# y_true = Y_test\n",
        "# print(f'the recall is :{recall_score(y_true,predicted)}', end = '\\n')\n",
        "# print(f'the precision is :{precision_score(y_true,predicted)}', end = '\\n')\n",
        "# print(f'the f1 score is :{f1_score(y_true,predicted)}', end = '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sasas"
      ],
      "metadata": {
        "id": "KVmVtHzO3JBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjQMnhE9jSeV"
      },
      "outputs": [],
      "source": [
        "predicted = model_if.predict(test_data)\n",
        "predicted = np.where(predicted == 1,0,1)\n",
        "\n",
        "y_true = test_fraud\n",
        "print(f'the recall is :{recall_score(y_true,predicted)}', end = '\\n')\n",
        "print(f'the precision is :{precision_score(y_true,predicted)}', end = '\\n')\n",
        "print(f'the f1 score is :{f1_score(y_true,predicted)}', end = '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J4gXTnoMIHxl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
