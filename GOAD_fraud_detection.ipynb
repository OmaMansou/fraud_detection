{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Readding and preparing the data:"
      ],
      "metadata": {
        "id": "TAMM_2LTjVpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import datetime\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# reading the dataset\n",
        "path = '/content/drive/MyDrive/'\n",
        "try:\n",
        "  data = pd.read_pickle(path + 'fraud_dataset.pkl')\n",
        "except:\n",
        "  data = pd.read_csv(path + 'fraud_dataset.csv')\n",
        "  # peakle data \n",
        "  data.to_pickle('/content/drive/MyDrive/fraud_dataset.pkl')\n",
        "\n",
        "\n",
        "data['hour'] = pd.to_datetime(data['datetime']).dt.hour\n",
        "data.drop('datetime', axis = 1, inplace = True)\n",
        "# dropping the useless column 'Unnamed: 0'\n",
        "data.drop('Unnamed: 0', axis = 1, inplace = True)\n",
        "\n",
        "train_columns = ['acquirerid', 'agriculture_list', 'rollingsum_card_merchant_24h','bankid', 'batchamount','card','emv','cup','construction_list','mean_merchant_amount','mcc', 'list_bankid_ci', 'list_bankid_b', 'fuel_list', 'pospayenvcode','merchant', 'medic_list',\n",
        "                   'rollingcount_card_merchant_600s','riskmerchant', 'resp_code', 'rollingcount_merchant_24h','rollingcount_merchant_900s','rollingsum_card_24h','rollingsum_merchant_24h','rollingsum_merchant_900s',\n",
        "                   'hour', 'trc', 'travel_list', 'terminal', 'super_market_list']\n",
        "\n",
        "# let's shuffle the data first\n",
        "data = data.sample(frac=1).reset_index(drop = True)\n",
        "\n",
        "data  = data.iloc[:200000]\n",
        "train_data = data[:150000]\n",
        "train_data = train_data[train_data.fraud == 0]\n",
        "X_train = train_data[train_columns]\n",
        "\n",
        "test_data = data[150000:]\n",
        "X_test,Y_test = test_data[train_columns], test_data['fraud']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqwydps6jWiF",
        "outputId": "b00a35d9-dcfa-43cb-cce7-6e352f8db3aa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformations "
      ],
      "metadata": {
        "id": "KaziA7QaiX5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import abc\n",
        "import itertools\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import apply_affine_transform\n",
        "\n",
        "\n",
        "def get_transformer(type_trans):\n",
        "    if type_trans == 'complicated':\n",
        "        tr_x, tr_y = 8, 8\n",
        "        transformer = Transformer(tr_x, tr_y)\n",
        "        return transformer\n",
        "    elif type_trans == 'simple':\n",
        "        transformer = SimpleTransformer()\n",
        "        return transformer\n",
        "\n",
        "\n",
        "class AffineTransformation(object):\n",
        "    def __init__(self, flip, tx, ty, k_90_rotate):\n",
        "        self.flip = flip\n",
        "        self.tx = tx\n",
        "        self.ty = ty\n",
        "        self.k_90_rotate = k_90_rotate\n",
        "\n",
        "    def __call__(self, x):\n",
        "        res_x = x\n",
        "        if self.flip:\n",
        "            res_x = np.fliplr(res_x)\n",
        "        if self.tx != 0 or self.ty != 0:\n",
        "            res_x = apply_affine_transform(res_x,\n",
        "            tx=self.tx, ty=self.ty, channel_axis=2, fill_mode='reflect')\n",
        "        if self.k_90_rotate != 0:\n",
        "            res_x = np.rot90(res_x, self.k_90_rotate)\n",
        "        return res_x\n",
        "\n",
        "\n",
        "class AbstractTransformer(abc.ABC):\n",
        "    def __init__(self):\n",
        "        self._transformation_list = None\n",
        "        self._create_transformation_list()\n",
        "\n",
        "    @property\n",
        "    def n_transforms(self):\n",
        "        return len(self._transformation_list)\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def _create_transformation_list(self):\n",
        "        return\n",
        "\n",
        "    def transform_batch(self, x_batch, t_inds):\n",
        "        assert len(x_batch) == len(t_inds)\n",
        "\n",
        "        transformed_batch = x_batch.copy()\n",
        "        for i, t_ind in enumerate(t_inds):\n",
        "            transformed_batch[i] = self._transformation_list[t_ind](transformed_batch[i])\n",
        "        return transformed_batch\n",
        "\n",
        "\n",
        "class Transformer(AbstractTransformer):\n",
        "    def __init__(self, translation_x=8, translation_y=8):\n",
        "        self.max_tx = translation_x\n",
        "        self.max_ty = translation_y\n",
        "        super().__init__()\n",
        "\n",
        "    def _create_transformation_list(self):\n",
        "        transformation_list = []\n",
        "        for is_flip, tx, ty, k_rotate in itertools.product((False, True),\n",
        "                                                           (0, -self.max_tx, self.max_tx),\n",
        "                                                           (0, -self.max_ty, self.max_ty),\n",
        "                                                           range(4)):\n",
        "            transformation = AffineTransformation(is_flip, tx, ty, k_rotate)\n",
        "            transformation_list.append(transformation)\n",
        "        self._transformation_list = transformation_list\n",
        "        return transformation_list\n",
        "\n",
        "\n",
        "class SimpleTransformer(AbstractTransformer):\n",
        "    def _create_transformation_list(self):\n",
        "        transformation_list = []\n",
        "        for is_flip, k_rotate in itertools.product((False, True),\n",
        "                                                    range(4)):\n",
        "            transformation = AffineTransformation(is_flip, 0, 0, k_rotate)\n",
        "            transformation_list.append(transformation)\n",
        "        self._transformation_list = transformation_list\n",
        "        return transformation_list"
      ],
      "metadata": {
        "id": "jCiVhBnIh1kK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wideresnet"
      ],
      "metadata": {
        "id": "vVVVwS7mkA1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import numpy as np\n",
        "\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if isinstance(m, nn.Linear):\n",
        "        init.xavier_normal_(m.weight, gain=np.sqrt(2.0))\n",
        "    elif classname.find('Conv') != -1:\n",
        "        init.xavier_normal_(m.weight, gain=np.sqrt(2.0))\n",
        "    elif classname.find('Linear') != -1:\n",
        "        init.eye_(m.weight)\n",
        "    elif classname.find('Emb') != -1:\n",
        "        init.normal(m.weight, mean=0, std=0.01)\n",
        "\n",
        "class netC5(nn.Module):\n",
        "    def __init__(self, d, ndf, nc):\n",
        "        super(netC5, self).__init__()\n",
        "        self.trunk = nn.Sequential(\n",
        "        nn.Conv1d(d, ndf, kernel_size=1, bias=False),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Conv1d(ndf, ndf, kernel_size=1, bias=False),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Conv1d(ndf, ndf, kernel_size=1, bias=False),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Conv1d(ndf, ndf, kernel_size=1, bias=False),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Conv1d(ndf, ndf, kernel_size=1, bias=False),\n",
        "        )\n",
        "        self.head = nn.Sequential(\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Conv1d(ndf, nc, kernel_size=1, bias=True),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        tc = self.trunk(input)\n",
        "        ce = self.head(tc)\n",
        "        return tc, ce\n",
        "\n",
        "\n",
        "class netC1(nn.Module):\n",
        "    def __init__(self, d, ndf, nc):\n",
        "        super(netC1, self).__init__()\n",
        "        self.trunk = nn.Sequential(\n",
        "        nn.Conv1d(d, ndf, kernel_size=1, bias=False),\n",
        "        )\n",
        "        self.head = nn.Sequential(\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Conv1d(ndf, nc, kernel_size=1, bias=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        tc = self.trunk(input)\n",
        "        ce = self.head(tc)\n",
        "        return tc, ce"
      ],
      "metadata": {
        "id": "hFoO2aeKkFId"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimization_tc"
      ],
      "metadata": {
        "id": "KFYhgVTnibNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "#import fcnet as model\n",
        "from sklearn.metrics import precision_recall_fscore_support as prf\n",
        "\n",
        "def tc_loss(zs, m):\n",
        "    means = zs.mean(0).unsqueeze(0)\n",
        "    res = ((zs.unsqueeze(2) - means.unsqueeze(1)) ** 2).sum(-1)\n",
        "    pos = torch.diagonal(res, dim1=1, dim2=2)\n",
        "    offset = torch.diagflat(torch.ones(zs.size(1))).unsqueeze(0).cuda() * 1e6\n",
        "    neg = (res + offset).min(-1)[0]\n",
        "    loss = torch.clamp(pos + m - neg, min=0).mean()\n",
        "    return loss\n",
        "\n",
        "def f_score(scores, labels, ratio):\n",
        "    thresh = np.percentile(scores, ratio)\n",
        "    y_pred = (scores >= thresh).astype(int)\n",
        "    y_true = labels.astype(int)\n",
        "    precision, recall, f_score, support = prf(y_true, y_pred, average='binary')\n",
        "    return f_score\n",
        "\n",
        "\n",
        "class TransClassifierTabular():\n",
        "    def __init__(self, args):\n",
        "        self.ds = args.dataset\n",
        "        self.m = args.m\n",
        "        self.lmbda = args.lmbda\n",
        "        self.batch_size = args.batch_size\n",
        "        self.ndf = args.ndf\n",
        "        self.n_rots = args.n_rots\n",
        "        self.d_out = args.d_out\n",
        "        self.eps = args.eps\n",
        "\n",
        "        self.n_epoch = args.n_epoch\n",
        "        if args.dataset == \"thyroid\" or args.dataset == \"arrhythmia\":\n",
        "            self.netC = netC1(self.d_out, self.ndf, self.n_rots).cuda()\n",
        "        else:\n",
        "            self.netC = netC5(self.d_out, self.ndf, self.n_rots).cuda()\n",
        "        weights_init(self.netC)\n",
        "        self.optimizerC = optim.Adam(self.netC.parameters(), lr=args.lr, betas=(0.5, 0.999))\n",
        "\n",
        "\n",
        "    def fit_trans_classifier(self, train_xs, x_test, y_test, ratio):\n",
        "        labels = torch.arange(self.n_rots).unsqueeze(0).expand((self.batch_size, self.n_rots)).long().cuda()\n",
        "        celoss = nn.CrossEntropyLoss()\n",
        "        print('Training')\n",
        "        for epoch in range(self.n_epoch):\n",
        "            self.netC.train()\n",
        "            rp = np.random.permutation(len(train_xs))\n",
        "            n_batch = 0\n",
        "            sum_zs = torch.zeros((self.ndf, self.n_rots)).cuda()\n",
        "\n",
        "            for i in range(0, len(train_xs), self.batch_size):\n",
        "                self.netC.zero_grad()\n",
        "                batch_range = min(self.batch_size, len(train_xs) - i)\n",
        "                train_labels = labels\n",
        "                if batch_range == len(train_xs) - i:\n",
        "                    train_labels = torch.arange(self.n_rots).unsqueeze(0).expand((len(train_xs) - i, self.n_rots)).long().cuda()\n",
        "                idx = np.arange(batch_range) + i\n",
        "                xs = torch.from_numpy(train_xs[rp[idx]]).float().cuda()\n",
        "                tc_zs, ce_zs = self.netC(xs)\n",
        "                sum_zs = sum_zs + tc_zs.mean(0)\n",
        "                tc_zs = tc_zs.permute(0, 2, 1)\n",
        "\n",
        "                loss_ce = celoss(ce_zs, train_labels)\n",
        "                er = self.lmbda * tc_loss(tc_zs, self.m) + loss_ce\n",
        "                er.backward()\n",
        "                self.optimizerC.step()\n",
        "                n_batch += 1\n",
        "\n",
        "            means = sum_zs.t() / n_batch\n",
        "            means = means.unsqueeze(0)\n",
        "            self.netC.eval()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                val_probs_rots = np.zeros((len(y_test), self.n_rots))\n",
        "                for i in range(0, len(x_test), self.batch_size):\n",
        "                    batch_range = min(self.batch_size, len(x_test) - i)\n",
        "                    idx = np.arange(batch_range) + i\n",
        "                    xs = torch.from_numpy(x_test[idx]).float().cuda()\n",
        "                    zs, fs = self.netC(xs)\n",
        "                    zs = zs.permute(0, 2, 1)\n",
        "                    diffs = ((zs.unsqueeze(2) - means) ** 2).sum(-1)\n",
        "\n",
        "                    diffs_eps = self.eps * torch.ones_like(diffs)\n",
        "                    diffs = torch.max(diffs, diffs_eps)\n",
        "                    logp_sz = torch.nn.functional.log_softmax(-diffs, dim=2)\n",
        "\n",
        "                    val_probs_rots[idx] = -torch.diagonal(logp_sz, 0, 1, 2).cpu().data.numpy()\n",
        "\n",
        "                val_probs_rots = val_probs_rots.sum(1)\n",
        "                f1_score = f_score(val_probs_rots, y_test, ratio)\n",
        "                print(\"Epoch:\", epoch, \", fscore: \", f1_score)\n",
        "        return f1_score"
      ],
      "metadata": {
        "id": "shweEIB5iFuJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training:"
      ],
      "metadata": {
        "id": "nJp3F0d_imB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_real, val_fake = test_data[test_data.fraud == 0][train_columns], test_data[test_data.fraud == 1][train_columns]\n",
        "\n",
        "import numpy as np\n",
        "#from data_loader import Data_Loader\n",
        "#import opt_tc_tabular as tc\n",
        "import argparse\n",
        "\n",
        "def load_trans_data(args):\n",
        "    \n",
        "    train_real = X_train\n",
        "    y_test_fscore = np.concatenate([np.zeros(len(val_real)), np.ones(len(val_fake))])\n",
        "    ratio = 100.0 * len(val_real) / (len(val_real) + len(val_fake))\n",
        "\n",
        "    n_train, n_dims = train_real.shape\n",
        "    rots = np.random.randn(args.n_rots, n_dims, args.d_out)\n",
        "\n",
        "    print('Calculating transforms')\n",
        "    x_train = np.stack([train_real.dot(rot) for rot in rots], 2)\n",
        "    val_real_xs = np.stack([val_real.dot(rot) for rot in rots], 2)\n",
        "    val_fake_xs = np.stack([val_fake.dot(rot) for rot in rots], 2)\n",
        "    x_test = np.concatenate([val_real_xs, val_fake_xs])\n",
        "    return x_train, x_test, y_test_fscore, ratio\n",
        "\n",
        "\n",
        "def train_anomaly_detector(args):\n",
        "    x_train, x_test, y_test, ratio = load_trans_data(args)\n",
        "    tc_obj = TransClassifierTabular(args)\n",
        "    f_score = tc_obj.fit_trans_classifier(x_train, x_test, y_test, ratio)\n",
        "    return f_score\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     parser = argparse.ArgumentParser()\n",
        "#     parser.add_argument('--lr', default=0.001, type=float)\n",
        "#     parser.add_argument('--n_rots', default=32, type=int)\n",
        "#     parser.add_argument('--batch_size', default=64, type=int)\n",
        "#     parser.add_argument('--n_epoch', default=25, type=int)\n",
        "#     parser.add_argument('--d_out', default=4, type=int)\n",
        "#     parser.add_argument('--dataset', default='thyroid', type=str)\n",
        "#     parser.add_argument('--exp', default='affine', type=str)\n",
        "#     parser.add_argument('--c_pr', default=0, type=int)\n",
        "#     parser.add_argument('--true_label', default=1, type=int)\n",
        "#     parser.add_argument('--ndf', default=8, type=int)\n",
        "#     parser.add_argument('--m', default=1, type=float)\n",
        "#     parser.add_argument('--lmbda', default=0.1, type=float)\n",
        "#     parser.add_argument('--eps', default=0, type=float)\n",
        "#     parser.add_argument('--n_iters', default=500, type=int)\n",
        "\n",
        "#     args = parser.parse_args()\n",
        "#     print(\"Dataset: \", args.dataset)\n",
        "\n",
        "#     if args.dataset == 'thyroid' or args.dataset == 'arrhythmia':\n",
        "#         n_iters = args.n_iters\n",
        "#         f_scores = np.zeros(n_iters)\n",
        "#         for i in range(n_iters):\n",
        "#             f_scores[i] = train_anomaly_detector(args)\n",
        "#         print(\"AVG f1_score\", f_scores.mean())\n",
        "#     else:\n",
        "#         train_anomaly_detector(args)\n",
        "\n",
        "# A solution is to create an Args class \n",
        "\n",
        "# this classe is just to replace argsparse \n",
        "class Args():\n",
        "  def __init__(self, depth, widen, batch_size,lr, n_epoch, type_trans, lmbda, m, reg, eps, class_ind,n_rots,d_out,ndf,n_iters,c_pr, dataset):\n",
        "    self.depth, self.widen, self.batch_size,self.lr, self.n_epoch, self.type_trans, self.lmbda, self.m, self.reg, self.eps, self.class_ind, self.n_rots, self.d_out,self.ndf,self.n_iters,self.c_pr, self.dataset= depth, widen, batch_size,lr, n_epoch, type_trans, lmbda, m, reg, eps, class_ind,n_rots,d_out,ndf,n_iters,c_pr,dataset\n",
        "args = Args(10, 4, 288,0.001,16,'complicated', 0.1,1,True,0,1,32,4,8,500,0, 'chora_zaml')\n",
        "\n",
        "train_anomaly_detector(args)\n",
        "\n"
      ],
      "metadata": {
        "id": "f8mvfSctii2o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "af99f10b-b493-42e1-e4e2-83ec9122abfd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating transforms\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-adc15eb9b0b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m288\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'complicated'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'chora_zaml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0mtrain_anomaly_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-adc15eb9b0b0>\u001b[0m in \u001b[0;36mtrain_anomaly_detector\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_anomaly_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_trans_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mtc_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransClassifierTabular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mf_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtc_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_trans_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-28d11758eefd>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetC1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_rots\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetC5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_rots\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mweights_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizerC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \"\"\"\n\u001b[0;32m--> 689\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \"\"\"\n\u001b[0;32m--> 689\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ]
    }
  ]
}